{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat((train_text, test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train.drop(['id', 'comment_text'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the target structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'num of labels')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x214074a0c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(20, 10))\n",
    "sb.countplot(data = train_target.sum(axis = 1), x = train_target.sum(axis = 1).index)\n",
    "plt.xlabel('num of labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'percentage of total labels')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x192848935f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize = (18, 10))\n",
    "sb.barplot(x = train_target.sum().index, y = train_target.sum()/train_target.shape[0])\n",
    "plt.xlabel('labels')\n",
    "plt.ylabel('percentage of total labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we seen above, this project is unbalance, and have multiple lables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf-idf method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_union\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=30000)\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    ngram_range=(1, 4),\n",
    "    max_features=30000)\n",
    "\n",
    "vectorizer = make_union(word_vectorizer, char_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-87b2473827ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrain_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtf_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    712\u001b[0m         transformers = Parallel(n_jobs=self.n_jobs)(\n\u001b[0;32m    713\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fit_one_transformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m             for _, trans, _ in self._iter())\n\u001b[0m\u001b[0;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_transformer_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_one_transformer\u001b[1;34m(transformer, X, y)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_fit_one_transformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1359\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \"\"\"\n\u001b[1;32m-> 1361\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 869\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m             \u001b[0mj_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m             \u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf_start = time.time()\n",
    "vectorizer.fit(all_text)\n",
    "train_feature = vectorizer.transform(train_text)\n",
    "test_feature = vectorizer.transform(test_text)\n",
    "tf_end = time.time()\n",
    "tf_time = tf_end - tf_start\n",
    "print(\"tf-idf method used {} seconds\".format(tf_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n"
     ]
    }
   ],
   "source": [
    "sample = train_text[0:1]\n",
    "print(train_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_feature = word_vectorizer.transform(sample)\n",
    "word_array = sample_feature.toarray()\n",
    "word_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GloVe method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 50 # how big is each word vector\n",
    "max_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a comment to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path_50d = open(\"F:\\word2vec\\glove\\glove.6B.50d.txt\", encoding = 'UTF-8')\n",
    "glove_path_25d = open(\"F:\\word2vec\\glove\\glove.twitter.27B.25d.txt\", encoding = 'UTF-8')\n",
    "glove_lines_50d = [line for line in glove_path_50d]\n",
    "glove_lines_25d = [line for line in glove_path_25d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_char(df, column):\n",
    "    df[column] = df[column].str.replace(r\"http\\S+\", \"\")\n",
    "    df[column] = df[column].str.replace(r\"http\", \"\")\n",
    "    df[column] = df[column].str.replace(r\"@\\S+\", \"\")\n",
    "    df[column] = df[column].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[column] = df[column].str.replace(r\"@\", \"at\")\n",
    "    df[column] = df[column].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array(lines):\n",
    "    key = lines[0]\n",
    "    value = np.asarray(lines.split()[1:], dtype = 'float32')\n",
    "    return key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用GloVe训练词向量所用的时间是39.69279384613037\n"
     ]
    }
   ],
   "source": [
    "gl_start = time.time()\n",
    "train_clearn = special_char(train, 'comment_text')\n",
    "train_clearn['comment_text'] = train_clearn['comment_text'].astype('str')\n",
    "train_clearn['comment_text'] = train_clearn['comment_text'].apply(tokenizer.tokenize)\n",
    "train_clearn['comment_text'] = train_clearn['comment_text'].apply(lambda vec: [word for word in vec if word not in stopwords])       \n",
    "test_clearn = special_char(test, 'comment_text')\n",
    "test_clearn['comment_text'] = test_clearn['comment_text'].astype('str')\n",
    "test_clearn['comment_text'] = test_clearn['comment_text'].apply(tokenizer.tokenize)\n",
    "test_clearn['comment_text'] = test_clearn['comment_text'].apply(lambda vec: [word for word in vec if word not in stopwords])\n",
    "\n",
    "train_words = [word for tokens in train_clearn['comment_text'] for word in tokens]\n",
    "train_sequence_length = [len(sequence) for sequence in train_clearn['comment_text']]\n",
    "num_train_words = len(set(train_words))\n",
    "\n",
    "test_words = [word for tokens in test_clearn['comment_text'] for word in tokens]\n",
    "test_sequence_length = [len(sequence) for sequence in test_clearn['comment_text']]\n",
    "num_test_words = len(set(test_words))\n",
    "\n",
    "all_words = [train_words, test_words]\n",
    "\n",
    "list_sentences_train = train['comment_text'].fillna('NA').values\n",
    "list_sentences_test = test['comment_text'].fillna('NA').values\n",
    "y = train[classes].values\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(all_words))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_train = pad_sequences(list_tokenized_train, maxlen = maxlen)\n",
    "X_test = pad_sequences(list_tokenized_test, maxlen = maxlen)\n",
    "\n",
    "word_dict = {}\n",
    "for line in glove_lines_50d:\n",
    "    key, value = get_array(line)\n",
    "    word_dict[key] = value\n",
    "\n",
    "all_emd = np.stack(word_dict.values())\n",
    "mean_emd, std_emd = all_emd.mean(), all_emd.std()\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(mean_emd, std_emd, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = word_dict.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "gl_end = time.time()\n",
    "gl_time = gl_end - gl_start\n",
    "print(\"GloVe method used {} sceconds\".format(gl_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f2002\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def schedule(ind):\n",
    "    a = [0.002,0.003, 0.000]\n",
    "    return a[ind]\n",
    "lr = callbacks.LearningRateScheduler(schedule)\n",
    "[X_train, X_val, y_train, y_val] = train_test_split(X_train, y, train_size=0.95)\n",
    "\n",
    "ra_val = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classes = []\n",
    "for col in train_target:\n",
    "    classes.append(col)\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_start = time.time()\n",
    "for class_name in classes:\n",
    "    target = train_target[class_name]\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(\n",
    "        classifier, train_feature, target, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(train_feature, target)\n",
    "    #submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "lr_end = time.time()\n",
    "lr_time = lr_end - lr_start\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "print('logisticregression method used {} seconds'.format(lr_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Input, LSTM, GRU, Embedding, Dropout, Activation, BatchNormalization, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=True)(inp)\n",
    "x = Bidirectional(LSTM(50, return_sequences=True,dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "import keras.backend as K\n",
    "def loss(y_true, y_pred):\n",
    "     return K.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f2002\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151592 samples, validate on 7979 samples\n",
      "Epoch 1/3\n",
      "151592/151592 [==============================] - 550s 4ms/step - loss: 0.0781 - acc: 0.8878 - val_loss: 0.0504 - val_acc: 0.9960\n",
      "\n",
      " ROC-AUC - epoch: 0 - score: 0.975748\n",
      "Epoch 2/3\n",
      "151592/151592 [==============================] - 537s 4ms/step - loss: 0.0504 - acc: 0.9849 - val_loss: 0.0470 - val_acc: 0.9956\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.982553\n",
      "Epoch 3/3\n",
      "151592/151592 [==============================] - 537s 4ms/step - loss: 0.0428 - acc: 0.9934 - val_loss: 0.0465 - val_acc: 0.9956\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.982683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20be783abe0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_start = time.time()\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=3, validation_data=(X_val, y_val), callbacks=[lr, ra_val])\n",
    "ls_end = time.time()\n",
    "ls_time = ls_end - ls_start\n",
    "print('LSTM method used {} seconds'.format(ls_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,    10,  4395,    24,  1035,   478,\n",
       "         128,   233,  2228,   397,  1669,    10,   304,     3,   143,\n",
       "         488,    12,    24,   669,  1958,   473,     7,    75,   554,\n",
       "         152, 10806,    17,   729,  5950,  5309,   596,    10,   310,\n",
       "        1221,    84,   251,  1210,   100,     7,     5,   461,    32,\n",
       "           6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "scores = []\n",
    "for label in classes:\n",
    "    target = y_tr[label]\n",
    "    classifier.fit(X_tr, target)\n",
    "    y_pre = classifier.predict(X_val)\n",
    "    scores.append(roc_auc_score(y_val[label], y_pre))\n",
    "    \n",
    "score = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5327702942012892\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f2002\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = []\n",
    "for label in classes:\n",
    "    target = y_tr[label]\n",
    "    ml = MLPClassifier(hidden_layer_sizes = (1000, 2), batch_size = 10000)\n",
    "    ml.fit(X_tr,target)\n",
    "    y_pre = ml.predict(X_val)\n",
    "    scores.append(roc_auc_score(y_val[label], y_pre))\n",
    "score = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.556422750611759"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ml.predict(test_text)\n",
    "result = pd.DataFrame()\n",
    "result['id'] = test['id']\n",
    "result['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'] = pred\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
